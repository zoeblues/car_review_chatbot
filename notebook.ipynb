{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "764a705a",
   "metadata": {},
   "source": [
    "# Below, I present a simple chatbot app that addresses diverse inquiries using LLMs. It runs fast locally thanks to the use of the pre-trained llms from hugging face.\n",
    "\n",
    "\n",
    "1. Classify car reviews\n",
    "2. Translate a car review from english to spanish\n",
    "3. Ask a question about a car review\n",
    "4. Summarize and analyze a car review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163101aa",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# View data and its columns, gather insights\n",
    "import pandas as pd\n",
    "data = pd.read_csv('car_reviews.csv', sep=';')\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c628a433",
   "metadata": {},
   "source": [
    "## 1. Sentiment analysis with classification LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede7ef44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the libraries \n",
    "import pandas as pd\n",
    "from transformers import logging, pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "logging.set_verbosity(logging.WARNING)\n",
    "\n",
    "# Loading sentiment analysis pipeline from hugging face\n",
    "model_name_sentiment = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=model_name_sentiment)\n",
    "data = pd.read_csv('car_reviews.csv', sep=';')\n",
    "\n",
    "# Predicting sentiment labels for the reviews\n",
    "predicted_labels = sentiment_pipeline(data['Review'].tolist())\n",
    "print(predicted_labels)\n",
    "\n",
    "# Converting output to {0,1} format\n",
    "predictions = [1 if r['label'].upper() == 'POSITIVE' else 0 for r in predicted_labels]\n",
    "true_labels = [1 if str(label).upper() == 'POSITIVE' else 0 for label in data['Class']]\n",
    "\n",
    "# Evaluating the classification accuracy and F1 score of predictions\n",
    "accuracy_result = accuracy_score(true_labels, predictions)\n",
    "f1_result = f1_score(true_labels, predictions, pos_label=1)\n",
    "\n",
    "print(f\"Predictions (1 is positive, 0 is negative): {predictions}\")\n",
    "print(f\"Accuracy: {accuracy_result:.2f}\")\n",
    "print(f\"F1 Score: {f1_result:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa01865",
   "metadata": {},
   "source": [
    "## 2. Translation LLM \n",
    "Extract and pass the first two sentences of the first review in the dataset to an English-to-Spanish translation LLM. Calculate the BLEU score to assess translation quality, using the content in reference_translations.txt as references."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5b29e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the additional libraries\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from transformers import pipeline\n",
    "import evaluate\n",
    "\n",
    "# Extracting and passing the first two sentences of the first review\n",
    "first_review = data['Review'][0]\n",
    "first_two_sentences = '.'.join(first_review.split('.')[:2]).strip() + '.'\n",
    "\n",
    "# Loading the English-to-Spanish translation LLM from hugging face\n",
    "model_name_translation = \"Helsinki-NLP/opus-mt-en-es\"\n",
    "translator = pipeline(\"translation_en_to_es\", model = model_name_translation)\n",
    "translated_review = translator(first_two_sentences, clean_up_tokenization_spaces=True)[0]['translation_text']\n",
    "\n",
    "# Evaluating the model with the BLEU SCORE\n",
    "with open(\"reference_translations.txt\", encoding='utf-8') as file:\n",
    "    reference_text = file.read().strip()\n",
    "\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "bleu_score = bleu.compute(predictions=[translated_review], references=[[reference_text]])\n",
    "\n",
    "print(\"BLEU score dictionary:\", bleu_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86e4a9d",
   "metadata": {},
   "source": [
    "## 3. Q&A LLM - asking a question about a review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a11e57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the additional libraries\n",
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline\n",
    "\n",
    "model_name_qa = \"deepset/minilm-uncased-squad2\"\n",
    "\n",
    "# Define the question and context (the second review in the dataset)\n",
    "question = \"What did he like about the brand?\"\n",
    "context_second = data['Review'][1]\n",
    "\n",
    "# Loading the model and tokenizer\n",
    "nlp = pipeline('question-answering', model=model_name_qa, tokenizer=model_name_qa)\n",
    "QA_input = {\n",
    "    'question': question,\n",
    "    'context': context_second\n",
    "}\n",
    "\n",
    "answer = nlp(QA_input)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b3bdd4",
   "metadata": {},
   "source": [
    "## 4. Summarizing LLM\n",
    "Summarize the last review from the dataset, between 50-55 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bd9409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the summarization pipeline from hugging face\n",
    "summarizer = pipeline(task=\"summarization\", model= \"facebook/bart-large-cnn\")\n",
    "last_review = data['Review'].iloc[-1]\n",
    "\n",
    "summary_output = summarizer(\n",
    "    last_review,\n",
    "    max_length=55,   \n",
    "    min_length=50\n",
    ")\n",
    "\n",
    "summarized_text = summary_output[0]['summary_text']\n",
    "print(summarized_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
